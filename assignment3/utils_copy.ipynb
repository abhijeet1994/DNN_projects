{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"utils_copy.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"YwTMWf9voxGP","colab_type":"code","outputId":"4d99d7ae-8b91-47d9-cad7-d30a22206d28","executionInfo":{"status":"ok","timestamp":1574895959982,"user_tz":300,"elapsed":20646,"user":{"displayName":"Abhijeet Arunkumar Mishra","photoUrl":"","userId":"02580029324233760324"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/My Drive/DL-Assignment 3"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n","/gdrive/My Drive/DL-Assignment 3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nKIbnmG-o-KI","colab_type":"code","outputId":"2b115e72-2076-4af5-aebf-3722d8738f26","executionInfo":{"status":"ok","timestamp":1574895966542,"user_tz":300,"elapsed":1551,"user":{"displayName":"Abhijeet Arunkumar Mishra","photoUrl":"","userId":"02580029324233760324"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /gdrive/My Drive/DL-Assignment 3/utils/xor\n"],"execution_count":30,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/DL-Assignment 3/utils/xor\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UBplA2bGrHPr","colab_type":"code","outputId":"32ab3aa4-3d6d-49cd-8457-19d7c67de655","executionInfo":{"status":"ok","timestamp":1574900076803,"user_tz":300,"elapsed":847,"user":{"displayName":"Abhijeet Arunkumar Mishra","photoUrl":"","userId":"02580029324233760324"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%%writefile rnn.py\n","#!/usr/bin/env python\n","import tensorflow as tf\n","from tensorflow.contrib.rnn import RNNCell\n","from tensorflow.python.framework import ops\n","from tensorflow.python.ops import clip_ops\n","from tensorflow.python.ops import init_ops\n","from tensorflow.python.ops import math_ops\n","from tensorflow.python.ops import nn_ops\n","from tensorflow.python.ops import array_ops\n","class MyLSTMCell(RNNCell):\n","    \"\"\"\n","    Your own basic LSTMCell implementation that is compatible with TensorFlow. To solve the compatibility issue, this\n","    class inherits TensorFlow RNNCell class.\n","\n","    For reference, you can look at the TensorFlow LSTMCell source code. It's located at tensorflow/tensorflow/python/ops/rnn_cell_impl.py.\n","    If you're using Anaconda, it's located at\n","    anaconda_install_path/envs/your_virtual_environment_name/site-packages/tensorflow/python/ops/rnn_cell_impl.py\n","\n","    So this is basically rewriting the TensorFlow LSTMCell, but with your own language.\n","    Also, you will find Colah's blog about LSTM to be very useful:\n","    http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n","    \"\"\"\n","\n","    def __init__(self, num_units, num_proj, forget_bias=1.0, activation=None):\n","        \"\"\"\n","        Initialize a class instance.\n","\n","        In this function, you need to do the following:\n","\n","        1. Store the input parameters and calculate other ones that you think necessary.\n","\n","        2. Initialize some trainable variables which will be used during the calculation.\n","\n","        :param num_units: The number of units in the LSTM cell.\n","        :param num_proj: The output dimensionality. For example, if you expect your output of the cell at each time step to be a 10-element vector, then num_proj = 10.\n","        :param forget_bias: The bias term used in the forget gate. By default we set it to 1.0.\n","        :param activation: The activation used in the inner states. By default we use tanh.\n","\n","        There are biases used in other gates, but since TensorFlow doesn't have them, we don't implement them either.\n","        \"\"\"\n","        super(MyLSTMCell, self).__init__(_reuse=True)\n","        #############################################\n","        #           TODO: YOUR CODE HERE            #\n","        self.num_units = num_units\n","        self.num_proj = num_proj\n","        self.forget_bias = forget_bias\n","        if activation:\n","          self.activation = activations.get(activation)\n","        else:\n","          self.activation = math_ops.tanh\n","        ##################SETTING UP VARIABLES\n","        ###FOR INPUT LAYER\n","        self.inp_weights = tf.get_variable(\"inp_weights\", [1+self.num_proj, self.num_units] , initializer=tf.random_normal_initializer())\n","        self.inp_bias = tf.get_variable(\"inp_bias\", [1, self.num_units] , initializer=tf.constant_initializer(0.0))\n","        ##For Update Layer\n","        self.up_weights_1 = tf.get_variable(\"up_weights_1\", [1+self.num_proj, self.num_units] , initializer=tf.random_normal_initializer())\n","        self.up_weights_2 = tf.get_variable(\"up_weights_2\", [1+self.num_proj, self.num_units] , initializer=tf.random_normal_initializer())\n","        self.up_bias_1 = tf.get_variable(\"up_bias_1\", [1, self.num_units] , initializer=tf.constant_initializer(0.0))\n","        self.up_bias_2 = tf.get_variable(\"up_bias_2\", [1, self.num_units] , initializer=tf.constant_initializer(0.0))\n","        ## for output layer\n","        self.out_weights_1 = tf.get_variable(\"out_weights_1\", [1+self.num_proj, self.num_proj] , initializer=tf.random_normal_initializer())\n","        self.out_weights_2 = tf.get_variable(\"out_weights_2\", [self.num_units, self.num_proj] , initializer=tf.random_normal_initializer())\n","        self.out_bias_1 = tf.get_variable(\"out_bias_1\", [1, self.num_proj] , initializer=tf.constant_initializer(0.0))\n","        self.out_bias_2 = tf.get_variable(\"out_bias_2\", [1, self.num_proj] , initializer=tf.constant_initializer(0.0))\n","        ##################VARIABLES SET UP\n","        #############################################\n","        #raise NotImplementedError('Please edit this function.')\n","            \n","    # The following 2 properties are required when defining a TensorFlow RNNCell.\n","    @property\n","    def state_size(self):\n","        \"\"\"\n","        Overrides parent class method. Returns the state size of of the cell.\n","\n","        state size = num_units + output_size\n","\n","        :return: An integer.\n","        \"\"\"\n","        #############################################\n","        #           TODO: YOUR CODE HERE            #\n","        self._state_size = self.num_units + self.num_proj\n","        return self._state_size\n","        #############################################\n","        #raise NotImplementedError('Please edit this function.')\n","\n","    @property\n","    def output_size(self):\n","        \"\"\"\n","        Overrides parent class method. Returns the output size of the cell.\n","\n","        :return: An integer.\n","        \"\"\"\n","        #############################################\n","        #           TODO: YOUR CODE HERE            #\n","        return self.num_proj\n","        #############################################\n","        #raise NotImplementedError('Please edit this function.')\n","\n","\n","    def call(self, inputs, state):\n","        \"\"\"\n","        Run one time step of the cell. That is, given the current inputs and the state from the last time step, calculate the current state and cell output.\n","\n","        You will notice that TensorFlow LSTMCell has a lot of other features. But we will not try them. Focus on the very basic LSTM functionality.\n","\n","        Hint 1: If you try to figure out the tensor shapes, use print(a.get_shape()) to see the shape.\n","\n","        Hint 2: In LSTM there exist both matrix multiplication and element-wise multiplication. Try not to mix them.\n","\n","        :param inputs: The input at the current time step. The last dimension of it should be 1.\n","        :param state:  The state value of the cell from the last time step. The state size can be found from function state_size(self).\n","        :return: A tuple containing (output, new_state). For details check TensorFlow LSTMCell class.\n","        \"\"\"\n","        #############################################\n","        #           TODO: YOUR CODE HERE            #\n","        sigmoid = math_ops.sigmoid\n","        \n","        \n","        \n","        c, h = array_ops.split(state, [64,2], 1) #use slice\n","        \n","        \n","\n","        ###### Forget Layer\n","        new_input = array_ops.concat([inputs, h], 1)\n","        forget_layer = math_ops.add(math_ops.matmul(new_input, self.inp_weights) , self.inp_bias) \n","        c = math_ops.multiply(c, sigmoid(forget_layer))\n","        \n","        ###### Update Layer\n","        up_layer_1 = sigmoid(math_ops.add(math_ops.matmul(new_input, self.up_weights_1) , self.up_bias_1))\n","        up_layer_2 = self.activation(math_ops.add(math_ops.matmul(new_input, self.up_weights_2) , self.up_bias_2))\n","        update = math_ops.multiply(up_layer_1,up_layer_2)\n","        c = math_ops.add(c + update)\n","        \n","        ####### Output Layer\n","        out_layer_1 = sigmoid(math_ops.add(math_ops.matmul(new_input, self.out_weights_1) , self.out_bias_1))\n","        out_layer_2 = self.activation(math_ops.add(math_ops.matmul(c, self.out_weights_2) , self.out_bias_2))\n","        h = math_ops.multiply(out_layer_1, out_layer_2)\n","        \n","        #comp_inputs = array_ops.concat([inputs, h], 1)\n","        state = array_ops.concat([c, h], 1)\n","        return state\n","        #############################################\n","        #raise NotImplementedError('Please edit this function.')"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Overwriting rnn.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fNF4DrfSrkKG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}