{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract files\n",
    "#file = open(\"./tiny-imagenet-200/wnids.txt\", \"r+\")\n",
    "#print (file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import numpy as np\n",
    "from scipy import ndimage, misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import keras\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, ZeroPadding2D, Conv2D, BatchNormalization, Activation, AveragePooling2D, DepthwiseConv2D, Flatten, Reshape, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Conv2D,MaxPooling2D,Flatten,Dropout,BatchNormalization, Activation\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_input2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/stanford results\r\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './stanford dogs/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b0eb15ee4b5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pwd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'./stanford dogs/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mclas_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/Images/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './stanford dogs/'"
     ]
    }
   ],
   "source": [
    "##\n",
    "# load all images in Training Directory\n",
    "##\n",
    "loaded_images = list()\n",
    "loaded_y = list()\n",
    "X_test = list()\n",
    "img_size =128\n",
    "!pwd\n",
    "path ='./stanford dogs/'\n",
    "for name in listdir(path):\n",
    "    print(name)\n",
    "clas_folder = path +'/Images/'\n",
    "\n",
    "dict={}\n",
    "for name in listdir(clas_folder):\n",
    "    print(name)\n",
    "list_clas_folder = listdir(clas_folder)\n",
    "#list_clas_folder.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(list_clas_folder)\n",
    "\n",
    "for i in range(num_classes):\n",
    "    dict[str(i)] = list_clas_folder[i]\n",
    "    folder_name = list_clas_folder[i]\n",
    "    image_path = clas_folder + folder_name\n",
    "    \n",
    "    for filename in listdir(image_path):\n",
    "        img_data = cv2.resize(cv2.imread(image_path + filename), (img_size, img_size),interpolation = cv2.INTER_AREA)\n",
    "        loaded_images.append(img_data)\n",
    "        loaded_y.append(i)\n",
    "print(\"Data Loaded\")\n",
    "plt.imshow(loaded_images[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = np.arange(len(loaded_y))\n",
    "np.random.shuffle(seq)\n",
    "print(\"shuffling..\")\n",
    "len(seq)\n",
    "X_train1 = list()\n",
    "y_train1 = list()\n",
    "#loaded_images = loaded_images*(1.0/255)\n",
    "for i in range(len(seq)):\n",
    "    X_train1.append(loaded_images[seq[i]])\n",
    "    y_train1.append(loaded_y[seq[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train1)\n",
    "plt.imshow(X_train[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = X_train*(1./255)\n",
    "y_train = np.asarray(y_train1)\n",
    "print(\"shuffling done...\")\n",
    "print(\"All data Loaded..\")\n",
    "plt.imshow(X_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical as one_hot\n",
    "y_train = one_hot(y_train)\n",
    "print(\"y_train_shape = \" , y_train.shape)\n",
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "X_test = X_train[-20000:-10000]\n",
    "y_test = y_train[-20000:-10000]\n",
    "X_train = X_train[:-20000]\n",
    "y_train = y_train[:-20000]\n",
    "print(\"X_val_shape = \" ,X_val.shape)\n",
    "print(\"X_train_shape = \" ,X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[7])\n",
    "datagen.fit(X_train)\n",
    "plt.imshow(X_train[7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Conv2D,MaxPooling2D,Flatten,Dropout,BatchNormalization, Activation\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_input2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, ZeroPadding2D, Conv2D, BatchNormalization, Activation, AveragePooling2D, DepthwiseConv2D, Flatten, Reshape, GlobalAveragePooling2D\n",
    "#import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, ZeroPadding2D, Conv2D, BatchNormalization, Activation, AveragePooling2D, DepthwiseConv2D, Flatten, Reshape, GlobalAveragePooling2D\n",
    "#import keras\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "\n",
    "base_model = MobileNet(include_top = False, weights ='imagenet', input_shape = (128,128,3))\n",
    "x = base_model.output\n",
    "x = Conv2D(64, kernel_size=1, strides=1, activation = 'relu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation ='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128, activation ='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "pred = Dense(200, activation ='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = base_model.input, outputs = pred)\n",
    "print(len(model.layers))\n",
    "for layer in model.layers[:-8]:\n",
    "    layer.trainable =False\n",
    "for layer in model.layers[-8:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Model(inputs=model.input, outputs =preds)\n",
    "from tensorflow.keras.optimizers import Adam as Adam\n",
    "\n",
    "adam = Adam(lr=0.001)\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.utils import multi_gpu_model\n",
    "#from keras.application import Xception\n",
    "\n",
    "#par_model = multi_gpu_model(model, gpus = 8)\n",
    "#par_model.compile(optimizer=adam,\n",
    "#              loss='categorical_crossentropy',\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_val, y_val))\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=256),\n",
    "                    steps_per_epoch=len(X_train) / 256, epochs=30, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('trained_model_mobilenet_64_all_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the exact same model purely from the file\n",
    "from keras.models import load_model\n",
    "#new_model = load_model('path_to_my_model.h5')\n",
    "classifierLoad = tf.keras.models.load_model('path_to_my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierLoad.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
